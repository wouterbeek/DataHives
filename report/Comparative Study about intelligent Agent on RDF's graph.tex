\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{enumitem}
\usepackage{amssymb}
\usepackage{color}
\usepackage[colorlinks,linkcolor=myorange, urlcolor=mygray, citecolor=mygreen, breaklinks, pagebackref]{hyperref}

\definecolor{mygray}{rgb}{0.7,0.7,0.7}
\definecolor{mygrey}{rgb}{0.5,0.5,0.5}
\definecolor{myorange}{rgb}{0.9,0.5,0}
\definecolor{mygreen}{rgb}{0.4,0.8,0}
\newenvironment{itemh}[0]{\begin{itemize}[label=$\heartsuit$, font=\color{mygray} \small]}{\end{itemize}}
\newenvironment{itemH}[0]{\begin{itemize}[label=$\heartsuit$, font=\color{mygray} \large]}{\end{itemize}}

\begin{document}
\title{Comparative Study about intelligent agent on RDF's graph\\
	\textit{Bachelor Project in Semantic Web using bee and ant agent}}
\author{	Baudouin Duthoit\\
		Student number : 2540566
	\and
		Wouter Beek
	\and
		Stefan Schlobach
	}
\maketitle

\abstract{
	RDF is a standard of W3C to enable computer and human to understand data, to give them sense.
	That is the Semantic Web.
	Data is stored in triples formed of a subject and a predicate and an object.
	Those triples themselves are on different computers well spread all over the web.
	More and more people are using the Semantic Web and so the online data is increasing a lot
	making the reasoning over the graph really complex and the more complex it is,
	the more we need efficient agents to increase performances.
	Our goal is to create agents that performs that reasoning base on the ants behaviour
	and compare them to the bee agents we already have, created last year by Christophe Guéret.
	Those agents are coded in JavaScript and perform as a Web application that any client can use,
	an example of the preexisting project can be found here \url{http://wouterblog.com/} .
}

\newpage

\tableofcontents

\newpage

\section{Introduction}
	%Introduction to RDF / Semantic Web
	\paragraph{} % Global presentation of RDF : The semantic web \& RDF
		Since its creation, the web see its data increasing exponentially.
		Those data are often unstructured and only human readable.
		Facing those two problems, scientists invented the semantic web to agregate data
		and make it easy to access for humans and computers.
		Those metadata are structured in triples that are stored online in a lot of different places in RDF
		(Resource Description Framework).
		Each triple is made of a subject, a predicate and an object.
		We can see it as 2 nodes and an arc from the subject to the object, thus we get an oriented graph.
		Also, there are several ways to store this data online.
	\paragraph{}	% Data format
		The most common one is to put the data on a database and query it via SPARQL,
		which is language that look like SQL but for RDF.
		Then we can send a query and get back some results that are in that database.
		As for SQL, SPARQL could built some complicated queries.
		The other common way of getting data is directly get files containing RDF in it (turtle, rdf, n3).
		The las one is by deferencing which i a mix of the two :
		it ask the server for data about a resource and get a file containing the data.
	\paragraph{}	%Introduction to other work
		Last year, another bachelor student worked on a similar project.
		His goal was to get back information from a search using agents acting like bees (in javascript) \cite{Kroes13}.
		We used his code as inspiration for our own bees agents (that are in prolog).
		That work was based on a paper \cite{Gueret10} about Swarm computing.
	%	\paragraph{}	%Introduction to DataHives project
	%	\subsection{Hypothesis}
		\begin{center}
			\textit{
			\textbf{Hypothesis :} The goal of this project is to create a new kind of agents based on a different behaviour,
			agent that we think more powerful than the previous one.}
		\end{center}

	%	\subsection{Evaluation}
		\paragraph{Evaluation:}
			We will verify the hypothesis via different criteria.
			The first way of compare two agents is quantitative using the number of discovered node (entailment regime).
			This one is relatively simpler to evaluate than the qualitative which require a human subjective interaction (user feedback).
			Those two methods will be used to compare 3 kind of agents:
		\begin{itemh}
			\item Random (base)
			\item Bee (already implemented)
			\item Ant (to be implemented)
		\end{itemh}

\newpage
\section{Planning}
	\subsection{Estimated tasks}
		Some high-level tasks, to be filled in later:
		\begin{itemH}
			\item Implementation framework:
				\begin{itemh}
					\item Have a look at the JS-based triple store rdfstore-js
					\item Integrate Pepijn’s work (as much as possible)  into the new implementation.
					\item Visualization (optional component) uses D3JS.
				\end{itemh}
			\item Strategies:
				\begin{itemh}
					\item Random movement + no communication.
					\item Bee: random node choice / communication / local traversal.
					\item Ant: movement based on pheromone values + communication via environment/graph annotation.
				\end{itemh}
			\item Evaluation:
				\begin{itemh}
					\item Quantify over the number of deductions (over time) achieved by a group of agents.
					\item Qualitative evaluation: more difficult…
				\end{itemh}
		\end{itemH}

\section{Work in Progress}
	\subsection{First try with RDFstore-js}
		\paragraph{} The first attempt to implement those agents was to use JS, based on the project :
		\url{https://githu.com/antoniogarrote/rdfstore-js}.
		Unfortunately, it has been misleading because the documentation was lacking
		and implementing functions was thus hard to do.
		It took me 3 days to understand how to load a store in local to work on it !
	\subsection{Work on DataHives \#1}
		\paragraph{} This is a submodule of the project Pragmatic Semantic.
		It already has random agents implemented.
		Those agents are defined by a cycle of action they perform : Navigate / Act / Communicate.
		The random agent go somewhere random, don't act nor communicate.
		We will implement naviguation, action and communication functions step by step,
		adding a few feature at a time to be sure to get something working in the end.
		The web interface will show where did the agents went (could be useful for qualitative evalutation).
		\paragraph{} To start the local server, we had to launch a command from the Pragmatic Semantic folder.
		The purpose of this command was to laucnh the local server.
		Then, on it, we could start some random agents using the simple dh\_test(\_) in prolog.
		After that, the visualization of the agents and their progress is at the web adresse localhost:3040.
		Unfortunately, the heavy structure was quite hard to manipulate correctly and didn't make a stand alone system.
		That why DataHives has been recast.
	\subsection{DataHives \#2 recast}
		\paragraph{} The recast makes the system more easy to use and more stand alone.
			The system also produced a picture of the crawled graph (100 most visited edges and their induced nodes).
		\paragraph{Evaluation \& Fitness.} The cycle has been updated, from this :
			"Navigate, Act, Communicate" to "Navigate, Act, Communicate, Evaluate".
			This evalutation is based on a fitness function that says if the agent fits or not,
			if it fitness is too low (typically below $0.5$), we kill it.
			For now, the fitness function is only a count of deduced information over the number of steps taken.
			But it will have some new features like taking dead end into account or
			fitness compare to a set of predefined triples.
		\paragraph{Rating the edges} is now really basic : if an agent go over an edge it leaves a virtual pheronmon,
			but soon we'll have some more complicated functions to devalue certain path if they lead to dead ends or
			if they don't lead to good information (depending on the previous described fitness function)

\section{Agents details \& behaviour}
	\paragraph{}
		All the agents are implemented in the same way.
		They follow a cycle of events and repeat that cycle.
		The cycle to follow is :
	\begin{center}
		Navigate / Act / Communicate / Evaluate
	\end{center}
	\paragraph{}
		Navigation is the function that decide WHERE the agent should go, depending on where it is already.
		In facts, this predicate pick a proposition between all the possibilities,
		those possibilities are all nodes that are neighbours to the one we are on.
		Unfortunately, thoses nodes could be literals and then we could get stuck on it because literals are linked to nothing.
		To avoid that, we have a backtrack function that keeps in mind the last position we were on.
	\paragraph{}
		Acting is where the agent do what it is meant for when it is on his own.
		In a clearer way it means that in this step the agent should work on the nodes it is on.
		This step is a selfish one where the other agents don't matter at all.
		The main action is only the deductive action of entailment.
		The rules for that can be found on the W3C web page \url{http://www.w3.org/TR/2014/REC-rdf11-mt-20140225/#rdfs-entailment}.
		We apply all of them to get some more information.
		Because all agents will have the same action, we decide to describe it here.
	\paragraph{}
		Communication is the main point of thoses agents.
		We try different kind of communication to see whether one is more efficient than the other
		and then compare the different kind of agents.
	\paragraph{}
		The evaluation part decides wether an agent diserve to continue his job or not.
		If it is judge inneficient then we throw it away using the exit function given at the creation of the agent.
		It's here where the fitness function should act.
	\subsection{Random Agent}
		\subsubsection{Navigate}
			The random agent is implemented to go randomly.
			It is initialized on a set of available URI where to begin.
			Then it goes, following "links".
			Those links are the predicates between 2 nodes of the Linked Open Data (LOD).
		\subsubsection{Communicate}
			The communication is not implemented to stick a really basic agent attitude that will serve as reference for efficiency.
		\subsubsection{Evaluate}
			The evaluation function is not set for this kind of agent that keep going whatever happens.
		\subsubsection{At exit}
			This predicate is not used because it is really bound to the evaluation that we discarded.
	\subsection{Ant Agent}
		\subsubsection{Navigate}
			The ant navigation is based on randomness but a weighted one.
			Like an ordinary ant, our agent has to pick a path, depending on the pheromons left on it.
			On the virtual web of the LOD, the pheromons are coeficient left on edges from one node to the other.
			If another ant went here before, the path get more value.			
		\subsubsection{Communicate}
			As said above, an ant leave pheromons in an intelligent way.
			The insect is looking for food (= information) outside (= on the LOD).
			When it has found something, it goes back to the anthill and leave pheromons on its way back as well.
			The main idea here is to upvalue a path which leads to food and devalue one that leads nowhere (ie dead-end path).
			To represent this in a virtual way here was our main ideas $c \in \mathbb{R}$:
			\begin{itemh}
				\item Devalue dead end path, using SPARQL queries to go back and degrade the weight of the path of $c$
				\item Adding $c$ to all the travelled path for each information deduced
				\item Adding the agent's current fitness to the current edge
			\end{itemh}
			\paragraph{}
				All those ideas needs to be evaluated and tried to see which one is the more efficient and if we could cross them.
		\subsubsection{Evaluate}
			The evaluation is where the fitness function enter in the game.
			For the ants, the fitness function is quantitative,
			counting the number of triples discovered via deduction and dividing it by the number of steps taken.
			If that number is bigger than 0.5, the agent can live, otherwise it dies lauching the exit function.
		\subsubsection{At exit}
			When the time comes for an agent to kill himself, it is decided that it must launch another agent to replace him.
			And so, the agent launch another agent that will work to get more information that the previous one if possible.
	\subsection{Bee Agent}
		\subsubsection{Navigate}
			A bee navigates randomly, whatever her role is.
			The scouts are wandering around to try to find information.
			When one succeed, it tells some others (called forager) to come and grab the pollen it has found.
		\subsubsection{Communicate}
			Here the communication is really simple.
			It directly contact the other agent to tell them something : the information is not sustainable, it is not stored somewhere.
			The information send is used instantly (it makes it more easy to set up).
		\subsubsection{Evaluate}
			The evaluation is based on the same criteria aof the one for the ants but here it trigger an action.
			If the fitness is big enough we send some foragers helping the scout, but if it is too low ... the agent get killed.
		\subsubsection{At exit}
			At the end of the thread we also ask for another agent to replace the bad one and keep sustainability in getting information.
			
\section{Evaluation of the difference between the agents}
	\subsection{Quantitative Evaluation}
		\paragraph{}
			First, we want to compare the agents over the number of deductions over the time they are running.
			It is something simple to count and objective, but it may be not relevant (if we look at the semantic part).
			To be more accurate, we will use 10 agents in waves of five.	% Because I decided so
			Of course, it is running on the same machine to have the same environment as much as possible.
		\begin{center}
			\begin{tabular}{|l|c|c|c|}
				\hline
				& Random & Bee & Ants\\
				\hline
				Time wave \#1 & 11 & 12 & 3 \\
				Time wave \#2 & 9  & 12 & 3 \\
				Time wave \#3 & 12 & 12 & 3 \\
				Time wave \#4 & 11 & 12 & 3 \\
				Time wave \#5 & 11 & 12 & 3 \\
				Time wave \#6 & 11 & 12 & 3 \\
				Time wave \#7 & 11 & 12 & 3 \\
				Time wave \#8 & 11 & 12 & 3 \\
				Time wave \#9 & 12 & 12 & 3 \\
				Time wave \#10& 11 & 12 & 3 \\
				\hline
				Average time  & 11 & 12 & 3 \\
				\hline
			\end{tabular}
		\end{center}
	\subsection{Robustness evaluation}
		\paragraph{}
			Our second evaluation will measure the bot robustness by counting the number of deaths
			in a certain time / steps / number of deductions
	\subsection{Fitness evolution}
		\paragraph{}
			Measuring how the fitness is evolving over time / number of steps to compare population of agents
\newpage
\section{Conclusion}
	

\newpage
\bibliographystyle{plain}
\bibliography{bibliography}
	Papers :
		\begin{itemh}
			\item Hayes2014 RDFS 1.1 Semantics (section 9.2.1 gives a fair overview).
			\item Pepijn Kroes, 2013, BNAIC poster.
			\item Kathrin Dentlez, Christophe Gueret, Stefan Schlobach, IEEE full paper.
		\end{itemh}
	Other links :
		\begin{itemh}
			\item\url{http://www.w3.org/TR/2014/REC-rdf11-mt-20140225/#rdfs-entailment}
			\item \url{http://www.doc.gold.ac.uk/~mas02gw/prolog_tutorial/prologpages/index.html#menu}
		\end{itemh}
\end{document}
